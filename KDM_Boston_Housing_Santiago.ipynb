{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "from keras import optimizers\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# === Utils Functions ===\n",
        "def dm2comp(dm):\n",
        "    '''Extract weights and vectors from a density matrix.'''\n",
        "    return dm[:, :, 0], dm[:, :, 1:]\n",
        "\n",
        "def pure2dm(psi):\n",
        "    '''Construct a pure-state density matrix from feature vectors.'''\n",
        "    ones = keras.ops.ones_like(psi[:, 0:1])\n",
        "    dm = keras.ops.concatenate((ones[:, np.newaxis, :], psi[:, np.newaxis, :]), axis=2)\n",
        "    return dm\n",
        "\n",
        "def dm_rbf_loglik(x, dm, sigma):\n",
        "    '''Log-likelihood under an RBF-kernel density matrix.'''\n",
        "    d = keras.ops.shape(x)[-1]\n",
        "    w, v = dm2comp(dm)\n",
        "    dist = keras.ops.sum((x[:, np.newaxis, :] - v) ** 2, axis=-1)\n",
        "    ll = keras.ops.log(\n",
        "        keras.ops.einsum('...i,...i->...', w,\n",
        "                         keras.ops.exp(-dist / (2 * sigma ** 2)) ** 2)\n",
        "        + 1e-12\n",
        "    )\n",
        "    coeff = d * keras.ops.log(sigma + 1e-12) + d * np.log(np.pi) / 2\n",
        "    return ll - coeff\n",
        "\n",
        "def dm_rbf_expectation(dm):\n",
        "    '''Expectation under an RBF-kernel density matrix.'''\n",
        "    w, v = dm2comp(dm)\n",
        "    return keras.ops.einsum('...i,...ij->...j', w, v)\n",
        "\n",
        "def dm_rbf_variance(dm, sigma):\n",
        "    '''Variance (trace) under an RBF-kernel density matrix.'''\n",
        "    sigma_adj = sigma / keras.ops.sqrt(2)\n",
        "    w, v = dm2comp(dm)\n",
        "    d = keras.ops.shape(v)[-1]\n",
        "    squared_norms = keras.ops.sum(v ** 2, axis=-1)\n",
        "    weighted_sq = keras.ops.einsum('...i,...i->...', w, squared_norms)\n",
        "    means = keras.ops.einsum('...i,...ij->...j', w, v)\n",
        "    sq_means = keras.ops.sum(means ** 2, axis=-1)\n",
        "    between = weighted_sq - sq_means\n",
        "    return between + d * (sigma_adj ** 2)\n",
        "\n",
        "def gauss_entropy_lb(d, sigma):\n",
        "    '''Lower bound on entropy of a Gaussian mixture.'''\n",
        "    return (d / 2.0) * (1.0 + keras.ops.log(2.0 * np.pi * (sigma ** 2)))\n",
        "\n",
        "def l1_loss(vals):\n",
        "    '''L1 regularization over normalized activations or components.'''\n",
        "    b_size = keras.ops.cast(keras.ops.shape(vals)[0], dtype=keras.float32)\n",
        "    vals_norm = keras.utils.normalize(vals, order=2, axis=1)\n",
        "    return keras.ops.sum(keras.ops.abs(vals_norm)) / b_size\n",
        "\n"
      ],
      "metadata": {
        "id": "m64_QJFBRH5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Kernel Layers ===\n",
        "class RBFKernelLayer(keras.layers.Layer):\n",
        "    def __init__(self, sigma, dim, trainable=True, min_sigma=1e-3, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.sigma = self.add_weight(\n",
        "            shape=(), initializer=keras.initializers.Constant(value=sigma), trainable=trainable\n",
        "        )\n",
        "        self.dim = dim\n",
        "        self.min_sigma = min_sigma\n",
        "\n",
        "    def call(self, A, B):\n",
        "        shape_A = keras.ops.shape(A)\n",
        "        A_norm = keras.ops.sum(A**2, axis=-1)[..., np.newaxis]\n",
        "        B_norm = keras.ops.sum(B**2, axis=-1)[np.newaxis, np.newaxis, :]\n",
        "        A_flat = keras.ops.reshape(A, [-1, shape_A[2]])\n",
        "        AB = keras.ops.matmul(A_flat, keras.ops.transpose(B))\n",
        "        AB = keras.ops.reshape(AB, [shape_A[0], shape_A[1], keras.ops.shape(B)[0]])\n",
        "        dist2 = keras.ops.clip(A_norm + B_norm - 2.*AB, 0., np.inf)\n",
        "        self.sigma.assign(keras.ops.clip(self.sigma, self.min_sigma, np.inf))\n",
        "        return keras.ops.exp(-dist2 / (2.*self.sigma**2))\n",
        "\n",
        "    def log_weight(self):\n",
        "        sigma_c = keras.ops.clip(self.sigma, self.min_sigma, np.inf)\n",
        "        return -self.dim * keras.ops.log(sigma_c + 1e-12) - self.dim * np.log(4 * np.pi)\n",
        "\n",
        "class CosineKernelLayer(keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        '''\n",
        "        Builds a layer that calculates the cosine kernel between two set of vectors\n",
        "        '''\n",
        "        super().__init__(**kwargs)\n",
        "        self.eps = 1e-6\n",
        "\n",
        "    def call(self, A, B):\n",
        "        '''\n",
        "        Input:\n",
        "            A: tensor of shape (bs, n, d)\n",
        "            B: tensor of shape (m, d)\n",
        "        Result:\n",
        "            K: tensor of shape (bs, n, m)\n",
        "        '''\n",
        "        A = keras.utils.normalize(A, order=2, axis=-1)\n",
        "        B = keras.utils.normalize(B, order=2, axis=-1)\n",
        "        K = keras.ops.einsum(\"...nd,md->...nm\", A, B)\n",
        "        return K\n",
        "\n",
        "    def log_weight(self):\n",
        "        return 0\n",
        "\n",
        "class KDMLayer(keras.layers.Layer):\n",
        "    def __init__(self, kernel, dim_x, dim_y, x_train=True, y_train=True, w_train=True,\n",
        "                 n_comp=0, l1_x=0., l1_y=0., l1_act=0., generative=0., **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.kernel, self.dim_x, self.dim_y = kernel, dim_x, dim_y\n",
        "        self.x_train, self.y_train, self.w_train = x_train, y_train, w_train\n",
        "        self.n_comp, self.l1_x, self.l1_y, self.l1_act, self.generative = (\n",
        "            n_comp, l1_x, l1_y, l1_act, generative\n",
        "        )\n",
        "        self.c_x = self.add_weight(\n",
        "            shape=(n_comp, dim_x), initializer=keras.initializers.random_normal(),\n",
        "            trainable=x_train, name=\"c_x\"\n",
        "        )\n",
        "        self.c_y = self.add_weight(\n",
        "            shape=(n_comp, dim_y),\n",
        "            initializer=keras.initializers.Constant(np.sqrt(1./dim_y)),\n",
        "            trainable=y_train, name=\"c_y\"\n",
        "        )\n",
        "        self.c_w = self.add_weight(\n",
        "            shape=(n_comp,),\n",
        "            initializer=keras.initializers.constant(1./n_comp),\n",
        "            trainable=w_train, name=\"c_w\"\n",
        "        )\n",
        "        self.eps = 1e-12\n",
        "\n",
        "    def call(self, inputs):\n",
        "        if self.l1_x:\n",
        "            self.add_loss(self.l1_x * l1_loss(self.c_x))\n",
        "        if self.l1_y:\n",
        "            self.add_loss(self.l1_y * l1_loss(self.c_y))\n",
        "        cw = keras.ops.abs(self.c_w)\n",
        "        cw_sum = keras.ops.clip(keras.ops.sum(cw), self.eps, np.inf)\n",
        "        self.c_w.assign(cw / cw_sum)\n",
        "\n",
        "        in_w = inputs[..., 0]\n",
        "        in_v = inputs[..., 1:]\n",
        "        out_vw = self.kernel(in_v, self.c_x)\n",
        "        out_w = cw[np.newaxis, np.newaxis, :] * keras.ops.square(out_vw)\n",
        "\n",
        "        if self.generative:\n",
        "            proj = keras.ops.einsum('...i,...ij->...', in_w, out_w)\n",
        "            logp = keras.ops.log(proj + self.eps) + self.kernel.log_weight()\n",
        "            self.add_loss(-self.generative * keras.ops.mean(logp))\n",
        "\n",
        "        out_w = keras.ops.maximum(out_w, self.eps)\n",
        "        out_w = out_w / keras.ops.sum(out_w, axis=2, keepdims=True)\n",
        "        out_w = keras.ops.einsum('...i,...ij->...j', in_w, out_w)\n",
        "\n",
        "        if self.l1_act:\n",
        "            self.add_loss(self.l1_act * l1_loss(out_w))\n",
        "\n",
        "        out_w = out_w[..., np.newaxis]\n",
        "        b = keras.ops.shape(out_w)[0]\n",
        "        out_y = keras.ops.broadcast_to(self.c_y[np.newaxis, ...], [b, self.n_comp, self.dim_y])\n",
        "        return keras.ops.concatenate((out_w, out_y), axis=2)\n",
        "\n",
        "    def get_config(self):\n",
        "        base = super().get_config()\n",
        "        return {**base, 'dim_x': self.dim_x, 'dim_y': self.dim_y, 'n_comp': self.n_comp}\n",
        "\n",
        "class KDMRegressModelRBF(keras.Model):\n",
        "    def __init__(self, encoded_size, dim_y, encoder, n_comp,\n",
        "                 sigma_x=0.1, min_sigma_x=1e-3,\n",
        "                 sigma_y=0.1, min_sigma_y=1e-3,\n",
        "                 x_train=True, y_train=True, w_train=True,\n",
        "                 generative=0., entropy_reg_x=0.,\n",
        "                 sigma_x_trainable=True, sigma_y_trainable=True,\n",
        "                 **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dim_y, self.encoded_size, self.n_comp = dim_y, encoded_size, n_comp\n",
        "        self.encoder, self.entropy_reg_x = encoder, entropy_reg_x\n",
        "        if generative > 0:\n",
        "            self.encoder.trainable = False\n",
        "\n",
        "        self.kernel = RBFKernelLayer(sigma_x, encoded_size,\n",
        "                                     trainable=sigma_x_trainable,\n",
        "                                     min_sigma=min_sigma_x)\n",
        "        self.kdm = KDMLayer(self.kernel, encoded_size, dim_y,\n",
        "                             x_train=x_train, y_train=y_train, w_train=w_train,\n",
        "                             n_comp=n_comp, generative=generative)\n",
        "        self.sigma_y = self.add_weight(\n",
        "            shape=(), initializer=keras.initializers.constant(sigma_y),\n",
        "            trainable=sigma_y_trainable, name=\"sigma_y\"\n",
        "        )\n",
        "        self.min_sigma_y = min_sigma_y\n",
        "\n",
        "    def call(self, inputs):\n",
        "        rho_x = pure2dm(self.encoder(inputs))\n",
        "        rho_y = self.kdm(rho_x)\n",
        "        self.sigma_y.assign(keras.ops.clip(self.sigma_y, self.min_sigma_y, np.inf))\n",
        "        return rho_y\n",
        "\n",
        "    def predict_reg(self, inputs, **kwargs):\n",
        "        rho_y = self.predict(inputs, **kwargs)\n",
        "        y_exp = keras.ops.convert_to_numpy(dm_rbf_expectation(rho_y))\n",
        "        y_var = keras.ops.convert_to_numpy(dm_rbf_variance(rho_y, self.sigma_y))\n",
        "        return y_exp, y_var\n",
        "\n",
        "    def get_sigmas(self):\n",
        "        return keras.ops.convert_to_numpy(self.kernel.sigma), keras.ops.convert_to_numpy(self.sigma_y)\n",
        "\n",
        "    def loglik(self, y_true, y_pred):\n",
        "        return -keras.ops.mean(dm_rbf_loglik(y_true, y_pred, self.sigma_y))\n",
        "\n",
        "    def init_components(self, samples_x, samples_y, init_sigma=False, sigma_mult=1):\n",
        "        enc = self.encoder.predict(samples_x)\n",
        "        if init_sigma:\n",
        "            np_enc = keras.ops.convert_to_numpy(enc)\n",
        "            d, _ = NearestNeighbors(n_neighbors=3).fit(np_enc).kneighbors(np_enc)\n",
        "            self.kernel.sigma.assign(np.mean(d[:, 2]) * sigma_mult)\n",
        "        self.kdm.c_x.assign(enc)\n",
        "        self.kdm.c_y.assign(samples_y)\n",
        "        self.kdm.c_w.assign(keras.ops.ones((self.n_comp,)) / self.n_comp)\n",
        "\n",
        "class KDMRegressModelCos(keras.Model):\n",
        "    def __init__(self, encoded_size, dim_y, encoder, n_comp,\n",
        "                 sigma_y=0.1, min_sigma_y=1e-3,\n",
        "                 x_train=True, y_train=True, w_train=True,\n",
        "                 generative=0., entropy_reg_x=0.,\n",
        "                 sigma_y_trainable=True,\n",
        "                 **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dim_y, self.encoded_size, self.n_comp = dim_y, encoded_size, n_comp\n",
        "        self.encoder, self.entropy_reg_x = encoder, entropy_reg_x\n",
        "        if generative > 0:\n",
        "            self.encoder.trainable = False\n",
        "\n",
        "        self.kernel = CosineKernelLayer()\n",
        "        self.kdm = KDMLayer(self.kernel, encoded_size, dim_y,\n",
        "                             x_train=x_train, y_train=y_train, w_train=w_train,\n",
        "                             n_comp=n_comp, generative=generative)\n",
        "        self.sigma_y = self.add_weight(\n",
        "            shape=(), initializer=keras.initializers.constant(sigma_y),\n",
        "            trainable=sigma_y_trainable, name=\"sigma_y\"\n",
        "        )\n",
        "        self.min_sigma_y = min_sigma_y\n",
        "\n",
        "    def call(self, inputs):\n",
        "        rho_x = pure2dm(self.encoder(inputs))\n",
        "        rho_y = self.kdm(rho_x)\n",
        "        self.sigma_y.assign(keras.ops.clip(self.sigma_y, self.min_sigma_y, np.inf))\n",
        "        return rho_y\n",
        "\n",
        "    def predict_reg(self, inputs, **kwargs):\n",
        "        rho_y = self.predict(inputs, **kwargs)\n",
        "        y_exp = keras.ops.convert_to_numpy(dm_rbf_expectation(rho_y))\n",
        "        y_var = keras.ops.convert_to_numpy(dm_rbf_variance(rho_y, self.sigma_y))\n",
        "        return y_exp, y_var\n",
        "\n",
        "    def get_sigmas(self):\n",
        "        return keras.ops.convert_to_numpy(self.kernel.sigma), keras.ops.convert_to_numpy(self.sigma_y)\n",
        "\n",
        "    def loglik(self, y_true, y_pred):\n",
        "        return -keras.ops.mean(dm_rbf_loglik(y_true, y_pred, self.sigma_y))\n",
        "\n",
        "    def init_components(self, samples_x, samples_y, sigma_mult=1):\n",
        "        enc = self.encoder.predict(samples_x)\n",
        "        self.kdm.c_x.assign(enc)\n",
        "        self.kdm.c_y.assign(samples_y)\n",
        "        self.kdm.c_w.assign(keras.ops.ones((self.n_comp,)) / self.n_comp)"
      ],
      "metadata": {
        "id": "NnLx9cZbTDsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = pd.read_csv('/content/housing.txt', header = None, sep = ' ')\n",
        "X = data.to_numpy()\n",
        "y = X[:,-1].reshape(-1, 1)\n",
        "X = X[:,0:-1]\n",
        "\n",
        "# Split data into 70% training and 30% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Training set size: {X_train.shape}\")\n",
        "print(f\"Test set size: {X_test.shape}\")\n",
        "\n",
        "X_train = np.asarray(X_train)\n",
        "X_test = np.asarray(X_test)\n",
        "\n",
        "scaler_x = StandardScaler()\n",
        "scaler_x.fit(X_train)\n",
        "X_train = scaler_x.transform(X_train)\n",
        "X_test = scaler_x.transform(X_test)\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0.2, np.pi/2-0.2))\n",
        "scaler.fit(y_train)\n",
        "y_train = scaler.transform(y_train)\n",
        "#y_test = scaler.transform(y_test))\n",
        "y_train = np.asarray(y_train).reshape(-1, 1)\n",
        "y_test = np.asarray(y_test).reshape(-1)\n",
        "\n",
        "print(f\"Training features size: {X_train.shape}\")\n",
        "print(f\"Training labels size: {y_train.shape}\")"
      ],
      "metadata": {
        "id": "q6ppbChPTIGT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "24f55acb-6c6c-45bf-e5f8-5b8687bbd30a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/housing.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-20a0688c3570>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/housing.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/housing.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Define los valores que quieres probar\n",
        "param_grid = {\n",
        "    'n_comp': [32],\n",
        "    'sigma_x': [0.1, 0.5],\n",
        "    'min_sigma_x': [1e-4],\n",
        "    'sigma_y': [0.1],\n",
        "    'min_sigma_y': [0.1, 0.5],\n",
        "    'learning_rate': [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 1e-1]\n",
        "}\n",
        "\n",
        "# Crear combinaciones de todos los parámetros\n",
        "param_combinations = list(product(*param_grid.values()))\n",
        "param_names = list(param_grid.keys())\n"
      ],
      "metadata": {
        "id": "kDBbSq5__HIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for combo in param_combinations:\n",
        "    params = dict(zip(param_names, combo))\n",
        "    print(f\"Evaluando combinación: {params}\")\n",
        "\n",
        "    encoder = keras.Sequential([keras.layers.Identity()])\n",
        "    model = KDMRegressModelRBF(\n",
        "        encoded_size=X_train.shape[1],\n",
        "        dim_y=y_train.shape[1],\n",
        "        encoder=encoder,\n",
        "        n_comp=params['n_comp'],\n",
        "        sigma_x=params['sigma_x'],\n",
        "        min_sigma_x=params['min_sigma_x'],\n",
        "        sigma_y=params['sigma_y'],\n",
        "        min_sigma_y=params['min_sigma_y'],\n",
        "        generative=1.0,\n",
        "        sigma_x_trainable=True,\n",
        "        sigma_y_trainable=False\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizers.Adam(learning_rate=params['learning_rate']),\n",
        "        loss=model.loglik\n",
        "    )\n",
        "\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
        "    idx = np.random.RandomState(42).randint(X_train.shape[0], size=params['n_comp'])\n",
        "    model.init_components(X_train[idx], y_train[idx], init_sigma=True)\n",
        "\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_split=0.2,\n",
        "        epochs=200,\n",
        "        batch_size=32,\n",
        "        callbacks=[early_stop],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Evaluar sobre el conjunto de prueba\n",
        "    y_pred, y_var = model.predict_reg(X_test)\n",
        "    y_pred = scaler.inverse_transform(y_pred)\n",
        "\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Guardar resultados\n",
        "    result = {**params, 'MAE': mae, 'MSE': mse, 'R2': r2}\n",
        "    results.append(result)\n"
      ],
      "metadata": {
        "id": "ibvX1Rj9_Hxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(results)\n",
        "# Ordenar por MAE o cualquier otra métrica\n",
        "results_df.sort_values(by='MAE').head()\n"
      ],
      "metadata": {
        "id": "tC6vFjj2_LUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
        "\n",
        "param_grid = {\n",
        "    'n_comp': [32,50,75,100,150],\n",
        "#    'sigma_x': [0.1,0.5,1.0],\n",
        "#    'min_sigma_x': [0.001, 0.01],\n",
        "    'sigma_y': [0.1,0.5,1.0],\n",
        "    'min_sigma_y': [0.01, 0.1],\n",
        "    'learning_rate': [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 1e-1]\n",
        "#    'sigma_y_trainable': [True, False],\n",
        "#    'generative': [0.0, 1.0],\n",
        "#    'kernel': ['rbf', 'cosine']\n",
        "}\n",
        "MAE = 100\n",
        "# Crear combinaciones de todos los parámetros\n",
        "param_combinations = list(product(*param_grid.values()))\n",
        "param_names = list(param_grid.keys())\n",
        "\n",
        "encoding_dim = 16\n",
        "\n",
        "results = []\n",
        "\n",
        "for combo in param_combinations:\n",
        "    params = dict(zip(param_names, combo))\n",
        "    print(f\"Evaluando combinación: {params}\")\n",
        "\n",
        "    encoder = encoder = Sequential([\n",
        "    Dense(X_train.shape[1], activation='relu'),\n",
        "    Dropout(0.1),\n",
        "    Dense(encoding_dim),\n",
        "    Activation('tanh')\n",
        "])\n",
        "    model = KDMRegressModelCos(\n",
        "        encoded_size=encoding_dim,\n",
        "        dim_y=y_train.shape[1],\n",
        "        encoder=encoder,\n",
        "        n_comp=params['n_comp'],\n",
        "        sigma_y=params['sigma_y'],\n",
        "        min_sigma_y=params['min_sigma_y'],\n",
        "        generative=1.0,\n",
        "        sigma_y_trainable=True\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizers.Adam(learning_rate=params['learning_rate']),\n",
        "        loss=model.loglik\n",
        "    )\n",
        "\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
        "    idx = np.random.RandomState(42).randint(X_train.shape[0], size=params['n_comp'])\n",
        "    #x_init_encoded = encoder(X_train[idx], training=False)\n",
        "    #model.init_components(x_init_encoded, y_train[idx])\n",
        "    model.init_components(X_train[idx], y_train[idx])\n",
        "\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_split=0.2,\n",
        "        epochs=200,\n",
        "        batch_size=32,\n",
        "        callbacks=[early_stop],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Evaluar sobre el conjunto de prueba\n",
        "    y_pred, y_var = model.predict_reg(X_test)\n",
        "    y_pred = scaler.inverse_transform(y_pred)\n",
        "\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    if mae < MAE:\n",
        "      history_best = history.history\n",
        "      MAE = mae\n",
        "    # Guardar resultados\n",
        "    result = {**params, 'MAE': mae, 'MSE': mse, 'R2': r2}\n",
        "    results.append(result)"
      ],
      "metadata": {
        "id": "psYbXy6BNtmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the learning curves\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history_best['loss'], label='Training Loss')\n",
        "plt.plot(history_best['val_loss'], label='Validation Loss')\n",
        "plt.title('Learning Curves')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d30Ib6uvTufy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(results)\n",
        "# Ordenar por MAE o cualquier otra métrica\n",
        "results_df.sort_values(by='MAE').head()"
      ],
      "metadata": {
        "id": "3WsnOiBTP7B9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}